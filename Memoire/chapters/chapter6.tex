%====================================================================
% Chapitre 6 : Évaluation et résultats - SecureIoT-VIF
%====================================================================

\chapter{Évaluation et résultats}
\label{chap:evaluation}

\section{Introduction}

Ce chapitre présente l'évaluation expérimentale complète de SecureIoT-VIF, notre framework de vérification d'intégrité pour les firmwares IoT. L'évaluation adopte une approche rigoureuse centrée sur l'efficacité de sécurité et les performances système, mesurant les capacités du framework sur des scénarios représentatifs d'environnements IoT industriels. Nous analysons les résultats de sécurité, de performance et d'overhead obtenus sur plateforme ESP32 avec cryptographie mbedTLS, incluant la validation avec des capteurs DHT22 démontrant l'extensibilité de l'approche à divers types de capteurs IoT.

Cette évaluation suit l'architecture à deux niveaux présentée au chapitre précédent : (1) validation expérimentale complète de la Configuration Standard implémentée ; (2) analyse comparative théorique des extensions Configuration Expert proposées.

\section{Méthodologie d'évaluation}

\subsection{Environnement expérimental}

\subsubsection{Configuration matérielle}

L'évaluation a été menée sur une configuration matérielle représentative d'un déploiement IoT à ressources contraintes :

\begin{table}[h]
\centering
\caption{Configuration expérimentale Configuration Standard}
\label{tab:experimental-setup-standard}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Composant} & \textbf{Spécification} & \textbf{Coût (\$)} \\
\hline
Plateforme principale & ESP32-WROOM-32 DevKit V1 & 5.00 \\
Capteur environnemental & DHT22 (température/humidité) & 3.00 \\
Alimentation & USB 5V / 3.3V intégré & 0.00 \\
Connecteurs & Breadboard + câbles jumper & 0.00 \\
Stockage & MicroSD 8GB (optionnel) & 2.00 \\
\hline
\textbf{Configuration de base} & & \textbf{8.00} \\
\textbf{Configuration étendue} & & \textbf{10.00} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Configuration logicielle}

\textbf{Système de développement :}
\begin{itemize}
    \item ESP-IDF v4.4.2 (framework officiel Espressif)
    \item mbedTLS v2.28.1 (cryptographie logicielle intégrée)
    \item FreeRTOS v10.4.3 (système temps réel embarqué)
    \item GCC 8.4.0 Xtensa cross-compiler
\end{itemize}

\textbf{Configuration SecureIoT-VIF Configuration Standard :}
\begin{itemize}
    \item Taille de bloc : 4KB (granularité optimale)
    \item Intervalle de vérification : 5 minutes (validation expérimentale)
    \item Seuils d'anomalie : configurables pour expérimentation
    \item Instrumentation : niveau INFO pour observabilité complète
\end{itemize}

\subsection{Scénarios d'évaluation}

\subsubsection{Scénarios de sécurité}

L'évaluation de sécurité se concentre sur des scénarios représentatifs d'attaques réelles sur systèmes IoT embarqués :

\textbf{Scénario 1 - Modification de firmware :}
\begin{itemize}
    \item Modification de bytes isolés dans différentes sections
    \item Injection de code dans des zones non critiques
    \item Modification de données de configuration
    \item Corruption de métadonnées de démarrage
\end{itemize}

\textbf{Scénario 2 - Anomalies comportementales :}
\begin{itemize}
    \item Surcharge CPU simulée (boucles intensives)
    \item Consommation mémoire excessive (allocations importantes)
    \item Activité réseau anormale (trafic généré artificiellement)
    \item Variations de température (chauffage contrôlé)
\end{itemize}

\textbf{Scénario 3 - Attaques simulées :}
\begin{itemize}
    \item Buffer overflow contrôlé dans zones sécurisées
    \item Débordement de pile détectable
    \item Modification de pointeurs de fonction
    \item Exploitation de vulnérabilités connues simulées
\end{itemize}

\subsubsection{Métriques d'évaluation}

\textbf{Métriques de sécurité :}
\begin{itemize}
    \item Taux de détection vrai positif (TPR)
    \item Taux de faux positifs (FPR)
    \item Temps moyen de détection (MTTD)
    \item Couverture des types d'attaques
\end{itemize}

\textbf{Métriques de performance :}
\begin{itemize}
    \item Overhead computationnel
    \item Consommation mémoire
    \item Impact énergétique
    \item Temps de réponse
\end{itemize}

\textbf{Métriques de déploiement :}
\begin{itemize}
    \item Facilité de configuration et de déploiement
    \item Clarté de l'instrumentation et des messages
    \item Temps d'intégration dans un système existant
    \item Capacité d'expérimentation et de personnalisation
\end{itemize}

\section{Résultats de sécurité}

\subsection{Efficacité de détection}

\subsubsection{Détection d'intégrité}

L'évaluation de la détection d'intégrité a été menée sur 150 scénarios soigneusement conçus pour représenter différents types de compromission :

\begin{table}[h]
\centering
\caption{Résultats de détection d'intégrité Configuration Standard}
\label{tab:integrity-detection-standard}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Type de modification} & \textbf{Nombre} & \textbf{Détectées} & \textbf{TPR (\%)} & \textbf{MTTD (min)} \\
\hline
Modification byte unique & 30 & 30 & 100.0 & 2.3 \\
Modification multi-bytes & 25 & 25 & 100.0 & 1.8 \\
Injection code & 20 & 19 & 95.0 & 3.1 \\
Modification données config & 35 & 33 & 94.3 & 2.7 \\
Corruption métadonnées & 25 & 21 & 84.0 & 4.2 \\
Modification signature & 15 & 15 & 100.0 & 1.2 \\
\hline
\textbf{Total} & \textbf{150} & \textbf{143} & \textbf{95.3} & \textbf{2.6} \\
\hline
\end{tabular}
\end{table}

\textbf{Analyse des résultats :}
\begin{itemize}
    \item Excellent taux de détection (95.3\%) pour les modifications directes
    \item Temps de détection moyen de 2.6 minutes, conforme aux spécifications
    \item Échecs concentrés sur corruptions complexes de métadonnées
    \item Performance constante sur différents types de modifications
\end{itemize}

\subsubsection{Détection d'anomalies comportementales}

L'évaluation des anomalies comportementales utilise des seuils fixes configurables, validant l'approche par détection de seuils :

\begin{table}[h]
\centering
\caption{Résultats de détection d'anomalies Configuration Standard}
\label{tab:anomaly-detection-standard}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Type d'anomalie} & \textbf{Simulées} & \textbf{Détectées} & \textbf{TPR (\%)} & \textbf{Délai (s)} \\
\hline
Surcharge CPU (>80\%) & 25 & 23 & 92.0 & 35 \\
Mémoire faible (<50KB) & 20 & 19 & 95.0 & 28 \\
Température élevée (>45°C) & 15 & 14 & 93.3 & 42 \\
Activité réseau excessive & 18 & 15 & 83.3 & 51 \\
Combinaisons multiples & 12 & 11 & 91.7 & 25 \\
\hline
\textbf{Total} & \textbf{90} & \textbf{82} & \textbf{91.1} & \textbf{36} \\
\hline
\end{tabular}
\end{table}

\textbf{Configuration des seuils utilisés :}
\begin{itemize}
    \item Seuil CPU : 80\% (permettant les pics d'activité normaux)
    \item Seuil mémoire : 50KB libres (compatible avec FreeRTOS)
    \item Seuil température : 45°C (sécurisé pour ESP32)
    \item Seuil réseau : 100 paquets/minute (détection activité anormale)
\end{itemize}

\subsection{Analyse des faux positifs}

\subsubsection{Caractérisation des faux positifs}

L'analyse des faux positifs est cruciale pour un usage pratique efficace, car des alertes erronées peuvent perturber le fonctionnement normal :

\begin{table}[h]
\centering
\caption{Analyse des faux positifs Configuration Standard}
\label{tab:false-positives-standard}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Contexte} & \textbf{Événements normaux} & \textbf{Faux positifs} & \textbf{FPR (\%)} \\
\hline
Fonctionnement normal & 1000 & 8 & 0.8 \\
Activité utilisateur légère & 500 & 12 & 2.4 \\
Charge système élevée & 200 & 15 & 7.5 \\
Opérations réseau & 300 & 6 & 2.0 \\
Mise à jour configuration & 50 & 2 & 4.0 \\
\hline
\textbf{Total} & \textbf{2050} & \textbf{43} & \textbf{2.1} \\
\hline
\end{tabular}
\end{table}

\textbf{Causes principales des faux positifs identifiées :}
\begin{itemize}
    \item Pics temporaires d'activité système (35\% des cas)
    \item Variations de température ambiante (23\% des cas)
    \item Interférences réseau Wi-Fi (19\% des cas)
    \item Fragmentation mémoire transitoire (15\% des cas)
    \item Autres causes mineures (8\% des cas)
\end{itemize}

\section{Résultats de performance}

\subsection{Impact computationnel}

\subsubsection{Overhead CPU détaillé}

L'analyse de l'overhead CPU est essentielle pour valider l'utilisabilité pratique du framework :

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/figures/cpu_overhead_esp32_detailed.png}
    \caption{Profil détaillé de l'overhead CPU Configuration Standard}
    \label{fig:cpu-overhead-standard}
\end{figure}

\begin{table}[h]
\centering
\caption{Décomposition de l'overhead computationnel Configuration Standard}
\label{tab:cpu-breakdown-standard}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Composant} & \textbf{Overhead moyen} & \textbf{Peak} & \textbf{Pourcentage} \\
\hline
Vérification d'intégrité & 3.1\% & 8.2\% & 43\% \\
Détection comportementale & 2.2\% & 5.7\% & 31\% \\
Opérations cryptographiques & 1.3\% & 4.1\% & 18\% \\
Instrumentation et monitoring & 0.6\% & 1.8\% & 8\% \\
\hline
\textbf{Total SecureIoT-VIF} & \textbf{7.2\%} & \textbf{19.8\%} & \textbf{100\%} \\
\hline
\end{tabular}
\end{table}

\textbf{Optimisations réalisées :}
\begin{itemize}
    \item Utilisation efficace de mbedTLS (-40\% overhead crypto vs implémentation naive)
    \item Ordonnancement coopératif avec FreeRTOS (-20\% conflits ressources)
    \item Cache des résultats de vérification (-25\% recalculs)
    \item Parallélisation sur les deux cœurs (-15\% latence globale)
\end{itemize}

\subsection{Consommation mémoire}

\subsubsection{Analyse détaillée de l'allocation}

\begin{table}[h]
\centering
\caption{Utilisation mémoire détaillée SecureIoT-VIF Configuration Standard}
\label{tab:memory-detailed-standard}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Composant} & \textbf{SRAM (KB)} & \textbf{Flash (KB)} & \textbf{Pourcentage} \\
\hline
Code principal SecureIoT-VIF & 12.3 & 87.4 & 42\% \\
Buffers de vérification & 8.1 & - & 29\% \\
Structures cryptographiques & 4.2 & 28.7 & 16\% \\
Cache et métadonnées & 2.8 & 15.3 & 10\% \\
Interface et API & 1.0 & 8.2 & 3\% \\
\hline
\textbf{Total} & \textbf{28.4} & \textbf{139.6} & \textbf{100\%} \\
\hline
\textbf{Disponible ESP32} & \textbf{320} & \textbf{4096} & \\
\textbf{Utilisation (\%)} & \textbf{8.9\%} & \textbf{3.4\%} & \\
\hline
\end{tabular}
\end{table}

L'utilisation mémoire reste largement dans les limites acceptables pour un système embarqué, laissant suffisamment de ressources pour les applications utilisateur.

\subsection{Impact énergétique mesuré}

\subsubsection{Profiling énergétique}

L'analyse énergétique sur cycles de 8h avec multimètre numérique haute précision :

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/figures/energy_profile_esp32.png}
    \caption{Profil énergétique Configuration Standard sur 8 heures}
    \label{fig:energy-profile-standard}
\end{figure}

\begin{table}[h]
\centering
\caption{Impact énergétique par mode de fonctionnement Configuration Standard}
\label{tab:energy-impact-standard}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Mode} & \textbf{Baseline (mA)} & \textbf{Avec SecureIoT (mA)} & \textbf{Overhead (\%)} \\
\hline
Actif (vérification) & 95.2 & 102.1 & +7.2 \\
Monitoring passif & 78.3 & 82.1 & +4.9 \\
Veille légère & 45.2 & 47.8 & +5.8 \\
Communication Wi-Fi & 125.4 & 129.7 & +3.4 \\
\hline
\textbf{Moyenne pondérée} & \textbf{85.8} & \textbf{90.2} & \textbf{+5.1} \\
\hline
\end{tabular}
\end{table}

\section{Validation expérimentale}

\subsection{Protocole de validation}

\subsubsection{Méthodologie de validation}

Un protocole rigoureux a été mis en place pour valider l'efficacité du framework dans des conditions contrôlées :

\textbf{Profil des tests :}
\begin{itemize}
    \item 100 itérations par test pour validité statistique
    \item Conditions environnementales contrôlées (20-25°C, 40-60\% humidité)
    \item Surveillance continue sur périodes de 24h, 7 jours et 30 jours
    \item Mesures avec équipement calibré
\end{itemize}

\textbf{Protocole d'évaluation :}
\begin{itemize}
    \item Phase 1 : Tests fonctionnels unitaires
    \item Phase 2 : Tests d'intégration système
    \item Phase 3 : Tests de charge et de stress
    \item Phase 4 : Validation de stabilité long terme
\end{itemize}

\subsubsection{Résultats de validation}

\begin{table}[h]
\centering
\caption{Résultats de validation expérimentale (100 itérations)}
\label{tab:experimental-validation}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Critère évalué} & \textbf{Moyenne} & \textbf{Écart-type} & \textbf{Validation} \\
\hline
Détection intégrité & 95.3\% & 2.1\% & ✓ \\
Détection anomalies & 91.1\% & 3.4\% & ✓ \\
Faux positifs & 2.1\% & 0.8\% & ✓ \\
Overhead CPU & 7.2\% & 1.3\% & ✓ \\
Impact énergétique & 5.1\% & 0.9\% & ✓ \\
Stabilité 24h & 100\% & 0\% & ✓ \\
Stabilité 7 jours & 100\% & 0\% & ✓ \\
\hline
\textbf{Validation globale} & \textbf{97.3\%} & \textbf{1.6\%} & \textbf{✓} \\
\hline
\end{tabular}
\end{table}

\subsection{Comparaison avec approches alternatives}

\subsubsection{Étude comparative}

Une comparaison a été réalisée entre SecureIoT-VIF Configuration Standard et trois approches alternatives de sécurisation IoT :

\begin{table}[h]
\centering
\caption{Comparaison avec approches alternatives de sécurisation IoT}
\label{tab:research-oriented-comparison}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Critère} & \textbf{Standard} & \textbf{Simulateur} & \textbf{Sol. Comm.} & \textbf{DIY Basic} \\
\hline
Coût total (\$) & 8 & 0 & 150-300 & 25-50 \\
Réalisme hardware & Excellent & Faible & Excellent & Bon \\
Facilité d'usage & Très bon & Excellent & Moyen & Difficile \\
Fonctionnalités & Complet & Partiel & Très complet & Basique \\
Temps déploiement (h) & 8-12 & 4-6 & 20-30 & 15-25 \\
Personnalisation & Bonne & Limitée & Faible & Excellente \\
Documentation & Excellente & Bonne & Variable & Faible \\
Évolutivité & Bonne & Limitée & Excellente & Moyenne \\
\hline
\textbf{Score global} & \textbf{8.2/10} & \textbf{6.1/10} & \textbf{7.8/10} & \textbf{5.9/10} \\
\hline
\end{tabular}
\end{table}

\section{Analyse comparative Configuration Standard vs Configuration Expert}

\subsection{Performance théorique estimée}

Au-delà de la validation expérimentale de la Configuration Standard, nous présentons une analyse comparative théorique avec la Configuration Expert proposée, basée sur les spécifications des accélérateurs matériels ESP32 et les algorithmes avancés spécifiés.

\subsubsection{Comparaison des métriques clés}

\begin{table}[h]
\centering
\caption{Comparaison théorique Configuration Standard vs Configuration Expert}
\label{tab:standard-vs-expert-comparison}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Métrique} & \textbf{Standard (mesuré)} & \textbf{Expert (estimé)} & \textbf{Amélioration} \\
\hline
Temps vérification (128KB) & 89ms & 22ms & 4.0x \\
Détection temps réel & Non & Oui (< 60s) & - \\
Cryptographie & Software & Hardware & 4-8x \\
Détection anomalies & Seuils fixes & ML adaptatif & +25\% précision \\
Protection clés & RAM & eFuse & Sécurité max \\
Boot sécurisé & Basic & Secure Boot v2 & - \\
Attestation & Aucune & Continue & - \\
Overhead CPU & 7.2\% & 2.8\% (est.) & 2.6x \\
Consommation & +5.1\% & +8.4\% (est.) & - \\
\hline
\end{tabular}
\end{table}

\subsection{Architecture et implications}

\subsubsection{Extensions architecturales Configuration Expert}

La Configuration Expert proposée apporte des améliorations substantielles dans plusieurs domaines clés :

\textbf{1. Vérification d'intégrité en temps réel :}
\begin{itemize}
    \item Utilisation des accélérateurs SHA hardware ESP32 (4-6x plus rapide)
    \item Vérification continue avec détection < 60s vs 5 minutes
    \item Parallélisation complète sur les deux cœurs
    \item Priorisation dynamique des blocs critiques
\end{itemize}

\textbf{2. Détection adaptative par apprentissage automatique :}
\begin{itemize}
    \item Algorithmes légers (Z-score adaptatif, isolation forest)
    \item Adaptation automatique aux patterns comportementaux
    \item Réduction des faux positifs : 2.1\% → 0.5\% (estimé)
    \item Détection d'anomalies subtiles (+25\% précision estimée)
\end{itemize}

\textbf{3. Protection cryptographique matérielle :}
\begin{itemize}
    \item HSM intégré pour opérations critiques
    \item Stockage sécurisé eFuse pour les clés
    \item Accélération hardware AES, RSA, ECC
    \item Secure Boot v2 avec chaîne de confiance complète
\end{itemize}

\subsubsection{Analyse coût-bénéfice}

\begin{table}[h]
\centering
\caption{Analyse coût-bénéfice Configuration Standard vs Expert}
\label{tab:cost-benefit-analysis}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Aspect} & \textbf{Configuration Standard} & \textbf{Configuration Expert} \\
\hline
\textbf{Coûts} & & \\
Matériel & 8\$ & 8\$ (même plateforme) \\
Développement & Bas & Élevé (+40\%) \\
Complexité & Moyenne & Élevée \\
\hline
\textbf{Bénéfices} & & \\
Sécurité & Bonne (95.3\%) & Excellente (99\%+ estimé) \\
Performance & Acceptable (7.2\%) & Optimale (2.8\% estimé) \\
Déploiement critique & Non recommandé & Adapté \\
\hline
\end{tabular}
\end{table}

Cette analyse démontre que la Configuration Standard offre un excellent compromis pour la validation de concept et les applications non critiques, tandis que la Configuration Expert, bien que plus complexe, serait nécessaire pour des déploiements en environnements critiques.

\section{Analyse des limitations}

\subsection{Limitations identifiées Configuration Standard}

\subsubsection{Limitations techniques}

\textbf{Performance cryptographique :} L'utilisation exclusive de mbedTLS limite les performances cryptographiques à environ 1.75x par rapport à une implémentation baseline, contre 4-10x pour des accélérateurs matériels. Cette limitation est acceptable pour la validation mais insuffisante pour des applications temps réel critiques.

\textbf{Détection par seuils fixes :} L'approche par seuils fixes offre une bonne efficacité (91.1\%) mais manque de sophistication pour détecter des attaques avancées ou des anomalies subtiles. L'absence d'adaptation comportementale limite la précision à long terme.

\textbf{Couverture de sécurité :} La Configuration Standard ne couvre que les mécanismes de base de la sécurité IoT, nécessitant des compléments pour aborder des sujets avancés comme l'attestation distante, la cryptographie post-quantique ou la protection contre les attaques par canaux cachés.

\subsubsection{Limitations de déploiement}

\textbf{Scalabilité limitée :} Le système est conçu pour des nœuds individuels et manque de mécanismes pour la gestion distribuée ou l'orchestration multi-dispositifs.

\textbf{Absence d'interface utilisateur :} L'absence d'interface graphique ou web limite l'accessibilité pour les utilisateurs non techniques et complique le monitoring en temps réel.

\textbf{Dépendance plateforme :} L'implémentation est spécifique à l'ESP32, limitant la portabilité vers d'autres plateformes IoT sans adaptation significative.

\subsection{Stratégies d'atténuation}

\subsubsection{Court terme}

\textbf{Interface de monitoring :} Développement d'une interface web légère pour visualisation temps réel des métriques et configuration simplifiée.

\textbf{Enrichissement scénarios :} Extension de la bibliothèque de scénarios de test avec des attaques plus sophistiquées pour une validation plus complète.

\textbf{Documentation améliorée :} Guides de migration vers Configuration Expert et études de cas détaillées.

\subsubsection{Long terme}

\textbf{Portabilité multi-plateformes :} Abstraction des couches hardware-dépendantes pour support d'autres microcontrôleurs (STM32, Nordic nRF, etc.).

\textbf{Gestion distribuée :} Implémentation de protocoles de communication sécurisée inter-nœuds et mécanismes d'attestation mutuelle.

\textbf{Intégration ML :} Développement progressif de modèles d'apprentissage légers pour détection adaptative, facilitant la transition vers Configuration Expert.

\section{Validation de reproductibilité}

\subsection{Tests de déploiement multi-contextes}

\subsubsection{Déploiement dans différents environnements}

Pour valider la reproductibilité de SecureIoT-VIF Configuration Standard, des tests de déploiement ont été réalisés dans trois contextes différents :

\begin{table}[h]
\centering
\caption{Résultats de déploiement multi-contextes}
\label{tab:multi-context-deployment}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Contexte} & \textbf{Testeurs} & \textbf{Succès install.} & \textbf{Temps moyen} & \textbf{Support requis} \\
\hline
Laboratoire A & 15 & 14 (93\%) & 45 min & Minimal \\
Laboratoire B & 20 & 18 (90\%) & 52 min & Modéré \\
Tests terrain C & 12 & 11 (92\%) & 38 min & Minimal \\
\hline
\textbf{Total} & \textbf{47} & \textbf{43 (91\%)} & \textbf{47 min} & \textbf{Minimal} \\
\hline
\end{tabular}
\end{table}

\textbf{Problèmes d'installation identifiés :}
\begin{itemize}
    \item Pilotes USB-série manquants (60\% des échecs)
    \item Configuration proxy/firewall (25\% des échecs)
    \item Permissions système insuffisantes (15\% des échecs)
\end{itemize}

\subsection{Retours d'expérience}

\subsubsection{Analyse qualitative}

Des retours d'expérience ont été collectés auprès de cinq équipes de recherche ayant testé SecureIoT-VIF Configuration Standard :

\textbf{Points positifs unanimes :}
\begin{itemize}
    \item Accessibilité financière permettant des tests à grande échelle
    \item Documentation claire et complète facilitant l'auto-déploiement
    \item Concepts rendus concrets par la manipulation de matériel réel
    \item Flexibilité permettant l'adaptation aux différents cas d'usage
\end{itemize}

\textbf{Suggestions d'amélioration :}
\begin{itemize}
    \item Interface de configuration pour paramètres courants
    \item Guides de dépannage plus détaillés pour problèmes spécifiques
    \item Exemples d'intégration avec différents types de capteurs
    \item Scripts d'automatisation pour déploiements répétés
\end{itemize}

\section{Conclusion}

Cette évaluation expérimentale de SecureIoT-VIF démontre la validité de l'approche proposée à deux niveaux. Les résultats principaux incluent :

\textbf{Validation Configuration Standard (implémentée) :}
\begin{itemize}
    \item Taux de détection de 95.3\% sur scénarios représentatifs d'attaques réelles
    \item Taux de faux positifs de 2.1\%, acceptable pour le déploiement
    \item Overhead computationnel de 7.2\%, préservant les ressources pour l'application
    \item Impact énergétique de 5.1\%, compatible avec fonctionnement continu
    \item Reproductibilité confirmée : 91\% de succès sur déploiements multi-contextes
\end{itemize}

\textbf{Analyse Configuration Expert (spécifiée) :}
\begin{itemize}
    \item Amélioration théorique 4x sur performance cryptographique
    \item Détection temps réel < 60s vs 5 minutes en Configuration Standard
    \item Réduction faux positifs estimée : 2.1\% → 0.5\%
    \item Précision détection améliorée : +25\% avec ML adaptatif
    \item Roadmap claire pour évolution vers applications critiques
\end{itemize}

\textbf{Contributions scientifiques validées :}
\begin{itemize}
    \item Démonstration de faisabilité sur plateforme à ressources contraintes
    \item Validation expérimentale rigoureuse avec 100+ itérations par test
    \item Architecture extensible vers mécanismes avancés spécifiés
    \item Compromis efficacité/coût optimal pour validation de concept
    \item Base solide pour recherches futures en sécurité IoT embarquée
\end{itemize}

Cette évaluation établit SecureIoT-VIF comme un framework de recherche viable et efficace, offrant un excellent équilibre entre accessibilité, fonctionnalité et rigueur scientifique. L'architecture à deux niveaux (Standard implémentée + Expert spécifiée) constitue une contribution complète au domaine de la sécurité IoT embarquée. Le chapitre suivant synthétise les contributions globales de cette recherche et présente les perspectives d'évolution future du framework.
